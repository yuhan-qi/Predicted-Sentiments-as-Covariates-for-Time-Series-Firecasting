{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f791a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general purpose packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "#data procedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "#transformers\n",
    "from transformers import AlbertTokenizer\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "#torch\n",
    "from keras.utils import np_utils\n",
    "import torch\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79a68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducibility\n",
    "seed=321\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce51ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('~/environment/data/sample_1000000_2005_2018_cleaned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848259ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1105058</th>\n",
       "      <td>2344352</td>\n",
       "      <td>Excellent food and customer service! My mom fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent food and customer service ! My mom f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index                                               text  stars  \\\n",
       "1105058  2344352  Excellent food and customer service! My mom fo...      5   \n",
       "\n",
       "                                              cleaned_text  \n",
       "1105058  Excellent food and customer service ! My mom f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7e917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    426404\n",
       "4    266102\n",
       "3    121561\n",
       "1    102135\n",
       "2     83798\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adff197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stars_reduce'] = data['stars']-1\n",
    "dummy_y = np_utils.to_categorical(data.stars_reduce)\n",
    "dummy_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0eefb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val,Y_train, Y_val = train_test_split(data.cleaned_text, dummy_y, test_size=0.2, \n",
    "                                                 stratify=dummy_y, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5fbb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=512\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d1280eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_albert(data,max_len=MAX_LEN) :\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "    \n",
    "    for sent in data:\n",
    "        encoded = tokenizer.encode(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding=False\n",
    "        )\n",
    "        input_ids.append(encoded)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92ceedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = tokenize_albert(X_train, MAX_LEN)\n",
    "val_ids = tokenize_albert(X_val, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d34244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by length\n",
    "train_samples = sorted(zip(train_ids, Y_train), key=lambda x: len(x[0]))\n",
    "val_samples = sorted(zip(val_ids, Y_val), key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2258304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest sample: 3\n",
      "Longest sample: 512\n"
     ]
    }
   ],
   "source": [
    "print('Shortest sample:', len(train_samples[0][0]))\n",
    "print('Longest sample:', len(train_samples[-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "274a767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_batches(samples, batch_size):\n",
    "    batch_ordered_sentences = []\n",
    "    batch_ordered_labels = []\n",
    "    text_data = samples.copy()\n",
    "    while len(text_data) > 0:\n",
    "        to_take = min(batch_size, len(text_data))\n",
    "        select = random.randint(0, len(text_data) - to_take)\n",
    "        batch = text_data[select:(select + to_take)]\n",
    "        batch_ordered_sentences.append([s[0] for s in batch])\n",
    "        batch_ordered_labels.append([s[1] for s in batch])\n",
    "        del text_data[select:select + to_take]\n",
    "    # print('\\n  DONE - {:,} batches.'.format(len(batch_ordered_sentences)))\n",
    "    return batch_ordered_sentences, batch_ordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6b7747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(batch_ordered_sentences, batch_ordered_labels):\n",
    "    py_inputs = []\n",
    "    py_attn_masks = []\n",
    "    py_labels = []\n",
    "    for (batch_inputs, batch_labels) in zip(batch_ordered_sentences, batch_ordered_labels):\n",
    "        batch_padded_inputs = []\n",
    "        batch_attn_masks = []\n",
    "\n",
    "        max_size = max([len(sen) for sen in batch_inputs])\n",
    "        for sen in batch_inputs:\n",
    "            num_pads = max_size - len(sen)\n",
    "            padded_input = sen + [tokenizer.pad_token_id]*num_pads\n",
    "            attn_mask = [1] * len(sen) + [0] * num_pads\n",
    "            batch_padded_inputs.append(padded_input)\n",
    "            batch_attn_masks.append(attn_mask)\n",
    "\n",
    "        py_inputs.append(torch.tensor(batch_padded_inputs))\n",
    "        py_attn_masks.append(torch.tensor(batch_attn_masks))\n",
    "        py_labels.append(torch.tensor(batch_labels))\n",
    "    return py_inputs,py_attn_masks,py_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2408a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred = np.argmax(preds, axis=1)+1\n",
    "    label = np.argmax(labels, axis=1)+1\n",
    "    # print('preds_flat ', pred)\n",
    "    # print('labels_flat ', label)\n",
    "    return np.sum(pred == label) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d77bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config type: <class 'transformers.models.albert.configuration_albert.AlbertConfig'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(pretrained_model_name_or_path='albert-base-v2',num_labels=5)\n",
    "print('Config type:', str(type(config)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76fae7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model type: <class 'transformers.models.albert.modeling_albert.AlbertForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path='albert-base-v2',config=config)\n",
    "print('\\nModel type:', str(type(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82824994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model to GPU...\n",
      "  GPU: Tesla V100-PCIE-16GB\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading model to GPU...')\n",
    "device = torch.device('cuda')\n",
    "print('  GPU:', torch.cuda.get_device_name(0))\n",
    "desc = model.to(device)\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52fea813",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize=8\n",
    "Epochs=2\n",
    "TotalSteps = len(train_ids) * Epochs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = TotalSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "182bc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, epochs, batch_size, train_data, val_data):\n",
    "    # store evaluation metrics\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        train_sentences, train_labels = select_batches(train_data, batch_size)\n",
    "        train_input_ids, train_attention_masks, train_type_ids = add_padding(train_sentences, train_labels)\n",
    "\n",
    "        \n",
    "        print('Training on {:,} batches...'.format(len(train_input_ids)))\n",
    "        t0 = time.time()\n",
    "        total_train_accuracy = 0\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step in tqdm(range(0, len(train_input_ids))):\n",
    "            b_input_ids = train_input_ids[step].to(device)\n",
    "            b_input_mask = train_attention_masks[step].to(device)\n",
    "            b_labels = train_type_ids[step].to(device)\n",
    "            model.zero_grad()\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask, \n",
    "                           labels=b_labels,\n",
    "                           return_dict = True)\n",
    "            loss = result.loss\n",
    "            total_train_loss += loss.item()\n",
    "            logits = result.logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            # print('logits ', logits)\n",
    "            # print('label_ids ', label_ids)\n",
    "            total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(train_input_ids)\n",
    "        avg_train_accuracy = total_train_accuracy / len(train_input_ids)\n",
    "        training_time = str(datetime.timedelta(seconds = int(round(time.time() - t0))))\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "        print(\"  Average training accuracy: {0:.4f}\".format(avg_train_accuracy))\n",
    "        print(\"  Training epcoh {} took: {:}\".format(epoch_i + 1, training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "        val_sentences, val_labels = select_batches(val_data, batch_size)\n",
    "        val_input_ids, val_attention_masks, val_type_ids = add_padding(val_sentences, val_labels)\n",
    "        print('Validating on {:,} batches...'.format(len(val_input_ids)))\n",
    "        t0 = time.time()\n",
    "        total_val_accuracy = 0\n",
    "        total_val_loss = 0\n",
    "        model.eval()\n",
    "        for step in tqdm(range(0, len(val_input_ids))):\n",
    "            b_input_ids = val_input_ids[step].to(device)\n",
    "            b_input_mask = val_attention_masks[step].to(device)\n",
    "            b_labels = val_type_ids[step].to(device)\n",
    "            with torch.no_grad():  \n",
    "                val_result = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       attention_mask=b_input_mask, \n",
    "                                       labels=b_labels)\n",
    "            logits = val_result.logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            loss = val_result.loss\n",
    "            total_val_loss += loss.item()\n",
    "            total_val_accuracy += flat_accuracy(logits, label_ids)\n",
    "        avg_val_accuracy = total_val_accuracy / len(val_input_ids)\n",
    "        avg_val_loss = total_val_loss / len(val_input_ids)\n",
    "        val_time = str(datetime.timedelta(seconds = int(round(time.time() - t0))))\n",
    "        print(\"\")\n",
    "        print(\"  Average validation loss: {0:.4f}\".format(avg_val_loss))\n",
    "        print(\"  Average validation accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
    "        print(\"  Validation epcoh {} took: {:}\".format(epoch_i + 1, val_time))\n",
    "        torch.save(model.state_dict(), '/home/ubuntu/environment/model/albert_512_2005_2018_{}'.format(epoch_i + 1))\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Training Accuracy':avg_train_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Loss':avg_val_loss,\n",
    "                'Validation Accuracy':avg_val_accuracy,\n",
    "                'Validation Time': val_time,\n",
    "            }\n",
    "        )\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "    total_time = str(datetime.timedelta(seconds = int(round(time.time() - total_t0))))\n",
    "    print(\"Total training took: {:}\".format(total_time))\n",
    "    return training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06840cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training on 100,000 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [2:29:31<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.2528\n",
      "  Average training accuracy: 0.7024\n",
      "  Training epcoh 1 took: 2:29:32\n",
      "Validating on 25,000 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 25000/25000 [11:26<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average validation loss: 0.2566\n",
      "  Average validation accuracy: 0.6930\n",
      "  Validation epcoh 1 took: 0:11:27\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training on 100,000 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [2:30:37<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.2452\n",
      "  Average training accuracy: 0.7142\n",
      "  Training epcoh 2 took: 2:30:38\n",
      "Validating on 25,000 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 25000/25000 [11:26<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average validation loss: 0.2612\n",
      "  Average validation accuracy: 0.6966\n",
      "  Validation epcoh 2 took: 0:11:27\n",
      "\n",
      "Training complete!\n",
      "Total training took: 5:24:08\n"
     ]
    }
   ],
   "source": [
    "history_albert = model_train(model, Epochs, BatchSize, train_samples, val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b10dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '/home/ubuntu/environment/model/albert_512_2005_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3212e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ubuntu/environment/performance/albert_512_history_2.json\", 'w') as f:\n",
    "    json.dump(history_albert, f, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a258b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.241503</td>\n",
       "      <td>0.720326</td>\n",
       "      <td>2:29:29</td>\n",
       "      <td>0.260697</td>\n",
       "      <td>0.69329</td>\n",
       "      <td>0:11:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>0.728069</td>\n",
       "      <td>2:30:54</td>\n",
       "      <td>0.260497</td>\n",
       "      <td>0.69438</td>\n",
       "      <td>0:11:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  Training Loss  Training Accuracy Training Time  Validation Loss  \\\n",
       "0      1       0.241503           0.720326       2:29:29         0.260697   \n",
       "1      2       0.236515           0.728069       2:30:54         0.260497   \n",
       "\n",
       "   Validation Accuracy Validation Time  \n",
       "0              0.69329         0:11:27  \n",
       "1              0.69438         0:11:28  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.DataFrame.from_records(history_albert)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "871376ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot accuracy\n",
    "# plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1, Epochs+1), history['Training Accuracy'])\n",
    "plt.plot(range(1, Epochs+1), history['Validation Accuracy'])\n",
    "plt.legend(['training_acc', 'validation_acc'])\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0176dd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss\n",
    "#plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1, Epochs+1), history['Training Loss'])\n",
    "plt.plot(range(1, Epochs+1), history['Validation Loss'])\n",
    "plt.legend(['training_loss', 'validation_loss'])\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024296c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_loaded = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path='albert-base-v2',config=config)\n",
    "model_loaded.load_state_dict(torch.load('/home/ubuntu/environment/model/albert_512_2005_2018_2'))\n",
    "device = torch.device('cuda')\n",
    "desc = model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e96073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test= pd.read_json('~/environment/data/restaurant_review_2019_cleaned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efc13136",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_star_reduce = data_test['stars']-1\n",
    "dummy_test_y = np_utils.to_categorical(test_star_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e8a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=512\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "BatchSize=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "252c0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(tokenizer, train_text, train_labels, batch_size, max_len):\n",
    "    batches_input_ids = []\n",
    "    batches_attention_masks = []\n",
    "    batches_labels = []\n",
    "    for i in tqdm(range(0, len(train_text), batch_size)):\n",
    "        encoded_dict = tokenizer.batch_encode_plus(\n",
    "            train_text[i:i+batch_size], # Batch of sentences to encode.\n",
    "            add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length = max_len,           # Pad & truncate all sentences.\n",
    "            padding = 'max_length',     # Pad all to the `max_length` parameter.\n",
    "            truncation = True,\n",
    "            return_attention_mask = True,   # Construct attn. masks.\n",
    "            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "        )\n",
    "        batches_input_ids.append(encoded_dict['input_ids'])\n",
    "        batches_attention_masks.append(encoded_dict['attention_mask'])\n",
    "        batches_labels.append(torch.tensor(train_labels[i:i+batch_size]))\n",
    "    return batches_input_ids,batches_attention_masks,batches_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "749587d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [14:39<00:00, 113.72it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_attention_masks, train_type_ids = fixed_padding(tokenizer, \n",
    "                                                                    X_train,\n",
    "                                                                    Y_train,\n",
    "                                                                    BatchSize, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e085666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25000/25000 [03:46<00:00, 110.24it/s]\n"
     ]
    }
   ],
   "source": [
    "val_input_ids, val_attention_masks, val_type_ids = fixed_padding(tokenizer, \n",
    "                                                                    X_val,\n",
    "                                                                    Y_val,\n",
    "                                                                    BatchSize, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38e758d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 65575/65575 [09:05<00:00, 120.12it/s]\n"
     ]
    }
   ],
   "source": [
    "test_input_ids, test_attention_masks, test_type_ids = fixed_padding(tokenizer, \n",
    "                                                                    data_test.cleaned_text,\n",
    "                                                                    dummy_test_y,\n",
    "                                                                    BatchSize, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37bd6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, batch_size, test_input_ids, test_attention_masks, test_type_ids):\n",
    "    t0 = time.time()\n",
    "    predictions , true_labels = [], []\n",
    "    \n",
    "    print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "    model.eval()\n",
    "    for step in tqdm(range(0, len(test_input_ids))):\n",
    "        b_input_ids = test_input_ids[step].to(device)\n",
    "        b_input_mask = test_attention_masks[step].to(device)\n",
    "        b_labels = test_type_ids[step].to(device)\n",
    "        with torch.no_grad():  \n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    test_time = str(datetime.timedelta(seconds = int(round(time.time() - t0))))\n",
    "    print(\"Total testing took: {:}\".format(test_time))\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d657eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 100,000 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [2:41:01<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing took: 2:41:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_evals, train_stars = model_predict(model_loaded, BatchSize, train_input_ids, train_attention_masks, train_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2037b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = np.argmax(np.concatenate(train_evals, axis=0), axis = 1)+1\n",
    "train_star = np.argmax(np.concatenate(train_stars, axis=0), axis = 1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b96aedbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65401,  13895,   1448,    282,    682],\n",
       "       [ 13546,  39028,  12463,   1283,    718],\n",
       "       [  2545,  14093,  56239,  20937,   3435],\n",
       "       [   690,   1254,  15260, 122879,  72799],\n",
       "       [   740,    301,   1525,  39047, 299510]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_star, train_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ff88829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7887    0.8004    0.7945     81708\n",
      "           2     0.5692    0.5822    0.5756     67038\n",
      "           3     0.6469    0.5783    0.6107     97249\n",
      "           4     0.6663    0.5772    0.6186    212882\n",
      "           5     0.7942    0.8780    0.8340    341123\n",
      "\n",
      "    accuracy                         0.7288    800000\n",
      "   macro avg     0.6930    0.6832    0.6867    800000\n",
      "weighted avg     0.7228    0.7288    0.7238    800000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_star, train_eval, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8105ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 25,000 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 25000/25000 [40:15<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing took: 0:40:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_evals, val_stars = model_predict(model_loaded, BatchSize, val_input_ids, val_attention_masks, val_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47eb9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_eval = np.argmax(np.concatenate(val_evals, axis=0), axis = 1)+1\n",
    "val_star = np.argmax(np.concatenate(val_stars, axis=0), axis = 1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6a0138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15802,  3777,   481,   122,   245],\n",
       "       [ 3758,  8803,  3510,   453,   236],\n",
       "       [  760,  3936, 12926,  5702,   988],\n",
       "       [  244,   407,  4485, 28474, 19610],\n",
       "       [  276,   121,   533, 11043, 73308]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val_star, val_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e22d45d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7583    0.7736    0.7658     20427\n",
      "           2     0.5165    0.5252    0.5208     16760\n",
      "           3     0.5893    0.5317    0.5590     24312\n",
      "           4     0.6218    0.5350    0.5752     53220\n",
      "           5     0.7767    0.8596    0.8160     85281\n",
      "\n",
      "    accuracy                         0.6966    200000\n",
      "   macro avg     0.6525    0.6450    0.6474    200000\n",
      "weighted avg     0.6890    0.6966    0.6908    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_star, val_eval, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86490a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 65,575 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 65575/65575 [1:45:27<00:00, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing took: 1:45:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds, stars = model_predict(model_loaded, BatchSize, test_input_ids, test_attention_masks, test_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdf7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(np.concatenate(preds, axis=0), axis = 1)+1\n",
    "star = np.argmax(np.concatenate(stars, axis=0), axis = 1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5718a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55571,   9033,   2513,    457,    830],\n",
       "       [ 11342,  18713,   8503,    966,    429],\n",
       "       [  2685,   8707,  28843,   9119,   1294],\n",
       "       [   527,    506,  11087,  60387,  28809],\n",
       "       [   632,    117,   1604,  41062, 220857]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(data_test['stars'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b77db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7854    0.8124    0.7987     68404\n",
      "           2     0.5047    0.4684    0.4859     39953\n",
      "           3     0.5489    0.5695    0.5590     50648\n",
      "           4     0.5392    0.5960    0.5662    101316\n",
      "           5     0.8757    0.8357    0.8552    264272\n",
      "\n",
      "    accuracy                         0.7327    524593\n",
      "   macro avg     0.6508    0.6564    0.6530    524593\n",
      "weighted avg     0.7391    0.7327    0.7353    524593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test['stars'], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b721e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['stars_albert_512'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849b4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_json('~/environment/data/restaurant_review_2019_cleaned_albert_512_prediction.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "padded_lengths = []\n",
    "\n",
    "for batch in train_input_ids:\n",
    "    for s in batch:\n",
    "        padded_lengths.append(len(s))\n",
    "smart_token_count = np.sum(padded_lengths)\n",
    "\n",
    "fixed_token_count = len(X_train) * MAX_LEN\n",
    "prcnt_reduced = (fixed_token_count - smart_token_count) / float(fixed_token_count) \n",
    "\n",
    "print('Total tokens:')\n",
    "print('   Fixed Padding: {:,}'.format(fixed_token_count))\n",
    "print('  Smart Batching: {:,}  ({:.1%} less)'.format(smart_token_count, prcnt_reduced))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
